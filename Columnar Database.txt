Columnar database

 -> the way data stored in a disk is different for columnar database
 -> In RDBMS data will be stored in record wise. Its like per one block of hard disk one row will be saved
 -> In Columnar database the data of a column of all rows will be stored in block
 
Ex:- User details
Id Name Age D.O.B
1   A    20  1990
2   B    30  2000

Here in RDBMS data will be stored in 1,A,20,1990 in one block of hard disk and 2,B,30,2000 in another block of harddisk
When we want to read a data record wise.it will first read first block and then second block. Here we need all the details of user so it is needed to read the entire block and entire hardisk.
If a new record is created, a new record will be inserted into a block in one write operation

Suppose if we want to plot a graph between D.O.B and sum(age) - Here we need only age and D.O.B
If data is stored in a RDBMS way we have to get data from all blocks of hard disk

In columnar database data will be stored in Id data - 1,2 in one block, A,B in another block, 20,30 in another block and 1990,2000 in another block
If we want a data of sum(age) we just need to iterate a age block and get the data. No need to scan the entire hard disk
If a new record is created with 3,C,25,1995 a four write operations will be performed to write Id value to one block, name to another block
--> So columnar database is not effective for frequent write operations system. It is suitable for analaytics query and historical data


When same types of data is stored in a block, compression can be applied and can save the size of hard disk

When a record is saved in a block, even there is a space remains in that block we cant store another record - So a space wastage
In columnar database, if a space is left in a block, another record column data can be stored there - So a space effective
 
 
How hard drives work
Hard disk drives consist of one or more magnetically-sensitive platters, an actuator arm with a read/write head on it for each platter, and a motor to spin the platters and move the arms. There is also an I/O controller and firmware that tells the hardware what to do and communicates with the rest of the system.

Each platter is organized into concentric circles called tracks. Tracks are divided into logical units called sectors. Each track and sector number results in a unique address that can be used to organize and locate data. Data is written to the nearest available area. There is an algorithm that processes the data before it’s written, allowing the firmware to detect and correct errors.

The platters spin at preset speeds (4200 rpm to 7200 rpm for consumer computers). Those speeds correlate to read/write rates. The higher the preset speed, the faster a hard drive will be able to read and write data.

Reading and writing
Each time you ask your computer to retrieve or update data, the I/O controller tells the actuator arm where that data is located, and the read/write head gathers the data by reading the presence or absence of a charge in each address. If the request was to update the data, the read/write head changes the charge on the affected track and sector.

The time it takes for the platter to spin and the actuator arm to find the correct track and sector is known as latency.


Buffer pool is stored in RAM


Horizontal Scaling -> Increasing the system resources to handle more requests -> Its cost effective
Vertical Scaling -> Increase the number of small sized servers to handle more requests -> Its not cost effective but there are advantages like
1. Fault tolerance -> THere is no single point of failure
2. Low Latency -> By placing the requests in multiple locations -> We can get the advantage of geographical locations

Database scaling
Vertical Scaling -> Its about saving the different tables in different servers -> Splitting of tables into different servers
Horizontal Scaling -> Its about splitting the same table rows into multiple servers based on some key -> Database sharding
Partition -> Splitting the table into multiple regions/partitions in the same server.

We can also use one master database system which handles only writes and replicating the data into slaves which only handles read requests
-> There is a problem of inconsistency here

CAP therom - Consistency, Availability and Partition -> We can give up Consistency and work on providing Availability and Partition.

************************************************
consistency — a guarantee that every node in a distributed cluster returns the same, most recent, successful write. consistency refers to every client having the same view of the data. there are various types of consistency models. consistency in cap (used to prove the theorem) refers to linearizability or sequential consistency, a very strong form of consistency.
availability — every non-failing node returns a response for all read and write requests in a reasonable amount of time. the key word here is every. to be available, every node on (either side of a network partition) must be able to respond in a reasonable amount of time.
partition tolerant — the system continues to function and upholds its consistency guarantees in spite of network partitions. network partitions are a fact of life. distributed systems guaranteeing partition tolerance can gracefully recover from partitions once the partition heals.
the c and a in acid represent different concepts than c and a in the cap theorem.

the cap theorem categorizes systems into three categories:

cp (consistent and partition tolerant) — at first glance, the cp category is confusing, i.e., a system that is consistent and partition tolerant but never available. cp is referring to a category of systems where availability is sacrificed only in the case of a network partition.
ca (consistent and available) — ca systems are consistent and available systems in the absence of any network partition. often a single node's db servers are categorized as ca systems. single node db servers do not need to deal with partition tolerance and are thus considered ca systems. the only hole in this theory is that single node db systems are not a network of shared data systems and thus do not fall under the preview of cap.
ap (available and partition tolerant) — these are systems that are available and partition tolerant but cannot guarantee consistency.
********************************************888
BASE -> Basically Available Soft sate and Eventual consistency -> No SQL
ACID -> Atomicity, Consistency, Isolation, Durability -> RDBMS

How distributed datastore works

-> Distributed datastore contains a multiple nodes among which data will be distributed
-> All the nodes are connected circuralry with a hash ring
-> Based on a hashing key that data will be decided to go into particular node
-> Each node has it own data and it also maintains the copy of part of other node
-> like this one node has a multiple copies in other nodes
-> So if one node goes down, we can still get the data from other nodes.
-> To scale up this nodes, We can add a nodes in between the nodes
-> All the nodes talk to each other using gossip protocol
-> this way nodes identify if any node is down or not and get rearaanged automatically